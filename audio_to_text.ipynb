{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1YsaiiHIafz_W_rgsgOsDyhCFVyIgCdkc",
      "authorship_tag": "ABX9TyM6eMznBzgicreqosNJztXv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a0ddbf9949fd40b0a8136ab436a4e077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4c8409b05024d0fb55fdd5121948365",
              "IPY_MODEL_ca3abbf388ce4366ae39e9bfad7ce14a",
              "IPY_MODEL_22b15e154f85455da1572bbb6e59a219"
            ],
            "layout": "IPY_MODEL_fe4771eca42a446ab67c2c5af0d5a1a1"
          }
        },
        "f4c8409b05024d0fb55fdd5121948365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7abd8b940e624c83ab62f0a6d1957d2d",
            "placeholder": "​",
            "style": "IPY_MODEL_fbefa4622e4c45de93aad6fdb284e180",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "ca3abbf388ce4366ae39e9bfad7ce14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a33fe83c3e449fba48783638c173309",
            "max": 1626,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98373ffe87164dd681d74b8bfa35d69c",
            "value": 1626
          }
        },
        "22b15e154f85455da1572bbb6e59a219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa75eaf42132438cb48d45b24020f811",
            "placeholder": "​",
            "style": "IPY_MODEL_c68bd976c5024b0aaaf7636711b6f902",
            "value": " 1.63k/1.63k [00:00&lt;00:00, 55.8kB/s]"
          }
        },
        "fe4771eca42a446ab67c2c5af0d5a1a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7abd8b940e624c83ab62f0a6d1957d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbefa4622e4c45de93aad6fdb284e180": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a33fe83c3e449fba48783638c173309": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98373ffe87164dd681d74b8bfa35d69c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa75eaf42132438cb48d45b24020f811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c68bd976c5024b0aaaf7636711b6f902": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eda4a066e1bc4232a68140c8a9982d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fffd8bd93fcf424e88aac92c06ef7228",
              "IPY_MODEL_d3b3fe216ba14cb98f829e391e0154a4",
              "IPY_MODEL_542be442b2a34070a0f2b9e3f2053d10"
            ],
            "layout": "IPY_MODEL_ec014a7da5bb4b3596dc568ef211e1d7"
          }
        },
        "fffd8bd93fcf424e88aac92c06ef7228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9b45c808a5a465ca5380544580086c3",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd1b97cc5e74fd6ad94ff0cc0cba1fb",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "d3b3fe216ba14cb98f829e391e0154a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82d600effcd74b5db81a5389e92e74fb",
            "max": 1625565295,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_16982d10cec54ad68ef98bcaa9157387",
            "value": 1625565295
          }
        },
        "542be442b2a34070a0f2b9e3f2053d10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eabf45cf1842458da886da35714c6fba",
            "placeholder": "​",
            "style": "IPY_MODEL_ffe9f968659a459db45adbc242ca9eb9",
            "value": " 1.63G/1.63G [00:16&lt;00:00, 187MB/s]"
          }
        },
        "ec014a7da5bb4b3596dc568ef211e1d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9b45c808a5a465ca5380544580086c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd1b97cc5e74fd6ad94ff0cc0cba1fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82d600effcd74b5db81a5389e92e74fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16982d10cec54ad68ef98bcaa9157387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eabf45cf1842458da886da35714c6fba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe9f968659a459db45adbc242ca9eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9895106f11b400985f7d75cb507d16c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_084f6302f56042e7994eac05fc50f434",
              "IPY_MODEL_567e2a0e94ce41d696a75b39f7a8fea7",
              "IPY_MODEL_b48a7efd85284a05ba3a90719f9e7d00"
            ],
            "layout": "IPY_MODEL_16f11b8928e34567987073e69d101de1"
          }
        },
        "084f6302f56042e7994eac05fc50f434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c48183227603488a876a7207890d9198",
            "placeholder": "​",
            "style": "IPY_MODEL_67dbb6dcbb254ac58e226d848ea1933d",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "567e2a0e94ce41d696a75b39f7a8fea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afdf334e65d547909f83e8e1e9102744",
            "max": 300,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd3e7ab64d6f43208f50f823b645918e",
            "value": 300
          }
        },
        "b48a7efd85284a05ba3a90719f9e7d00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e37815bf3a6b48abba1d728d8dcd9423",
            "placeholder": "​",
            "style": "IPY_MODEL_bba0f9d349fe44b1bc7883b26b0ef597",
            "value": " 300/300 [00:00&lt;00:00, 17.7kB/s]"
          }
        },
        "16f11b8928e34567987073e69d101de1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c48183227603488a876a7207890d9198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67dbb6dcbb254ac58e226d848ea1933d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afdf334e65d547909f83e8e1e9102744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd3e7ab64d6f43208f50f823b645918e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e37815bf3a6b48abba1d728d8dcd9423": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bba0f9d349fe44b1bc7883b26b0ef597": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df2706c9bc6e42dfb63736ab06c12116": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d92929ede105428c92c8b7825002244a",
              "IPY_MODEL_0171b3b9fb474209b80bb5a3f869161a",
              "IPY_MODEL_0de4b70fdd184239a9f9e121d2aaf011"
            ],
            "layout": "IPY_MODEL_0ee283f91f454c15aa71f3a0d3c5df54"
          }
        },
        "d92929ede105428c92c8b7825002244a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca18c9c94d6a493bbb4c1732776d99e5",
            "placeholder": "​",
            "style": "IPY_MODEL_f38375c9b56742cdab2dfa42569e789c",
            "value": "Downloading (…)olve/main/vocab.json: 100%"
          }
        },
        "0171b3b9fb474209b80bb5a3f869161a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd3b8e8d9d5345769ee9b4a2427924e4",
            "max": 798293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4303a705a015412bb48a8dc6c7e65378",
            "value": 798293
          }
        },
        "0de4b70fdd184239a9f9e121d2aaf011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20b43b0869824317a275adade9d19bc0",
            "placeholder": "​",
            "style": "IPY_MODEL_24292eca7c4946af913d9e6a47030d5a",
            "value": " 798k/798k [00:00&lt;00:00, 2.58MB/s]"
          }
        },
        "0ee283f91f454c15aa71f3a0d3c5df54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca18c9c94d6a493bbb4c1732776d99e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f38375c9b56742cdab2dfa42569e789c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd3b8e8d9d5345769ee9b4a2427924e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4303a705a015412bb48a8dc6c7e65378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20b43b0869824317a275adade9d19bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24292eca7c4946af913d9e6a47030d5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c259edf8d63b4266af688d48d9b9d110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e797d24f36fd45b79deefbec5f1a614e",
              "IPY_MODEL_e4b9d8a0e4b24b9590c1a7e8f7237b50",
              "IPY_MODEL_c9965c3733d5414b91ba8cc3b139e16a"
            ],
            "layout": "IPY_MODEL_e3a3f32b687c4bee942cc8a468f33655"
          }
        },
        "e797d24f36fd45b79deefbec5f1a614e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9e126db3a2649838c29e10d18612d08",
            "placeholder": "​",
            "style": "IPY_MODEL_5450be0a4b0b433eaa30cf493ac724d2",
            "value": "Downloading (…)olve/main/merges.txt: 100%"
          }
        },
        "e4b9d8a0e4b24b9590c1a7e8f7237b50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c263c0111d748c08763d4dc0ecfd644",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2adbaed710a5480a88965e330c70e827",
            "value": 456356
          }
        },
        "c9965c3733d5414b91ba8cc3b139e16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e056afa0d2f14372916ced6fd8cdfa9c",
            "placeholder": "​",
            "style": "IPY_MODEL_090b5f828d434a3db2e54a744e6eef7e",
            "value": " 456k/456k [00:00&lt;00:00, 1.84MB/s]"
          }
        },
        "e3a3f32b687c4bee942cc8a468f33655": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9e126db3a2649838c29e10d18612d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5450be0a4b0b433eaa30cf493ac724d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c263c0111d748c08763d4dc0ecfd644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2adbaed710a5480a88965e330c70e827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e056afa0d2f14372916ced6fd8cdfa9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "090b5f828d434a3db2e54a744e6eef7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fda1a8234524a669d79ba1f9adc3ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f46a20967be45778ef0e0f37ec6adb3",
              "IPY_MODEL_a97fa68447cc43c995fc5ff642dfddb2",
              "IPY_MODEL_6d3ebffbb7f34531a7b40d5690dd0829"
            ],
            "layout": "IPY_MODEL_b15bc735dfd344dd8318385613bb6a90"
          }
        },
        "8f46a20967be45778ef0e0f37ec6adb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_556b57be2a9746c89a06baaf5a9ef1e6",
            "placeholder": "​",
            "style": "IPY_MODEL_980dd03c509143a4b19355deaf1b74b6",
            "value": "Downloading (…)cial_tokens_map.json: 100%"
          }
        },
        "a97fa68447cc43c995fc5ff642dfddb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a35033b00c2a4457b06ad8212107a196",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1ab832e1c9d74b47967d16c3f3242aa1",
            "value": 239
          }
        },
        "6d3ebffbb7f34531a7b40d5690dd0829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_803c503cf77a440db0af909625d6a2e5",
            "placeholder": "​",
            "style": "IPY_MODEL_2ffac075b19c403d9dd6a3907cc1c482",
            "value": " 239/239 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "b15bc735dfd344dd8318385613bb6a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556b57be2a9746c89a06baaf5a9ef1e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "980dd03c509143a4b19355deaf1b74b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a35033b00c2a4457b06ad8212107a196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ab832e1c9d74b47967d16c3f3242aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "803c503cf77a440db0af909625d6a2e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ffac075b19c403d9dd6a3907cc1c482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mileslilly2/Lecture-Notes-Prototype/blob/main/audio_to_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gdslsl_4gQfT",
        "outputId": "74f6261a-0f30-49a5-8b25-393fb2bc6419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-h67657sd\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-h67657sd\n",
            "  Resolved https://github.com/openai/whisper.git to commit 6dea21fd7f7253bfe450f1e2512a0fe47ee2d258\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.3.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.13.1+cu116)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.10.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.9/dist-packages (12.1.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.9/dist-packages (0.25.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyaudio\n",
            "  Using cached PyAudio-0.2.13.tar.gz (46 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pyaudio\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyaudio \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for pyaudio\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build pyaudio\n",
            "\u001b[31mERROR: Could not build wheels for pyaudio, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyglet in /usr/local/lib/python3.9/dist-packages (2.0.5)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: playsound in /usr/local/lib/python3.9/dist-packages (1.3.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:7 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "27 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!pip install pytube\n",
        "!pip install pydub\n",
        "!pip install pyaudio\n",
        "!pip install pyglet\n",
        "!pip install playsound\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper \n",
        "model = whisper.load_model('large')\n",
        "import pytube\n",
        "import pydub\n",
        "from playsound import playsound\n",
        "import pyglet\n",
        "from moviepy.video.io.VideoFileClip import VideoFileClip\n",
        "import wave\n",
        "import io\n",
        "import os\n",
        "from moviepy.editor import *\n",
        "\n"
      ],
      "metadata": {
        "id": "PR1CLIDGg3WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b498606-9d63-4d58-fce6-51eae898c3a3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 2.87G/2.87G [00:35<00:00, 86.7MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Prompt the user to enter the YouTube video URL\n",
        "video_url = input(\"Enter the YouTube video URL: \")\n",
        "\n",
        "# Create a YouTube object and get the audio stream\n",
        "youtube = pytube.YouTube(video_url)\n",
        "audio_stream = youtube.streams.filter(subtype='mp4', only_audio=True).first()\n",
        "\n",
        "\n",
        "# Download the audio stream as an MP4 file\n",
        "mp4_file_path = audio_stream.download()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEcd6nc6rn4k",
        "outputId": "a2b0e57a-3b01-4f81-caf9-c5b1784bc4fa"
      },
      "execution_count": 36,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the YouTube video URL: https://www.youtube.com/watch?v=QDX-1M5Nj7s&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI&index=1&t=13s&ab_channel=AlexanderAmini\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mp4_file_path"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YKTGQ2_LwZxZ",
        "outputId": "82a2145b-93de-418c-b07d-36d86e14cfa0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/What is Salesforce Development (What its Like Being a Salesforce Developer).mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTmHUAV3wlf5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "# Specify the paths to the input and output files\n",
        "#input_file_path = 'input.mp4'\n",
        "output_file_path = 'output.wav'\n",
        "\n",
        "# Load the input video as an AudioSegment\n",
        "audio = AudioSegment.from_file(mp4_file_path, format='mp4')\n",
        "\n",
        "# Export the audio as a WAV file\n",
        "audio.export(output_file_path, format='wav')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woRgVfhGwRbQ",
        "outputId": "659bdb75-056b-4cf9-dcf7-0f1d53c23cdd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.BufferedRandom name='output.wav'>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#audio"
      ],
      "metadata": {
        "id": "tKSQazMShw8E"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#audio_stream"
      ],
      "metadata": {
        "id": "AyjAoubIqWf6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mp4_file_path"
      ],
      "metadata": {
        "id": "kmmUo0LIt6ch"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(audio)"
      ],
      "metadata": {
        "id": "8cUWAdvcui0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f792defd-c591-485d-c587-aecd21414983"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pydub.audio_segment.AudioSegment"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wav_file =  wave.open('output.wav', 'rb') \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M9iyEmMLoE3T"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "chunk_duration = 30\n",
        "# Get the total number of frames in the wav file\n",
        "total_frames = wav_file.getnframes()\n",
        "\n",
        "# Calculate the frame rate\n",
        "frame_rate = wav_file.getframerate()\n",
        "\n",
        "# Calculate the duration of the wav file in seconds\n",
        "duration = total_frames / frame_rate\n",
        "\n",
        "# Calculate the number of chunks\n",
        "num_chunks = int(duration / chunk_duration) + 1\n",
        "\n",
        "segments = []\n",
        "# Loop through the chunks and create a new file for each chunk\n",
        "for i in range(num_chunks):\n",
        "    # Calculate the start and end frame of the chunk\n",
        "    start_frame = int(i * chunk_duration * frame_rate)\n",
        "    end_frame = int(min((i + 1) * chunk_duration * frame_rate, total_frames))\n",
        "    \n",
        "    # Set the position of the wav file to the start frame of the chunk\n",
        "    wav_file.setpos(start_frame)\n",
        "    \n",
        "    # Read the chunk from the wav file\n",
        "    chunk_data = wav_file.readframes(end_frame - start_frame)\n",
        "    \n",
        "    # Create a new AudioSegment object from the chunk data\n",
        "    chunk = AudioSegment(\n",
        "        data=chunk_data,\n",
        "        sample_width=wav_file.getsampwidth(),\n",
        "        frame_rate=wav_file.getframerate(),\n",
        "        channels=wav_file.getnchannels()\n",
        "    )\n",
        "    \n",
        "    # Export the chunk as a new wav file\n",
        "    #chunk.export(f\"chunk_{i}.wav\", format=\"wav\")\n",
        "    segments.append(chunk)\n",
        "    \n",
        "# Close the wav file\n",
        "wav_file.close()\n",
        "'''"
      ],
      "metadata": {
        "id": "3VsntdIdhxiN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "d6bbe85f-ebfc-42de-ae44-3a12b855b05d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nchunk_duration = 30\\n# Get the total number of frames in the wav file\\ntotal_frames = wav_file.getnframes()\\n\\n# Calculate the frame rate\\nframe_rate = wav_file.getframerate()\\n\\n# Calculate the duration of the wav file in seconds\\nduration = total_frames / frame_rate\\n\\n# Calculate the number of chunks\\nnum_chunks = int(duration / chunk_duration) + 1\\n\\nsegments = []\\n# Loop through the chunks and create a new file for each chunk\\nfor i in range(num_chunks):\\n    # Calculate the start and end frame of the chunk\\n    start_frame = int(i * chunk_duration * frame_rate)\\n    end_frame = int(min((i + 1) * chunk_duration * frame_rate, total_frames))\\n    \\n    # Set the position of the wav file to the start frame of the chunk\\n    wav_file.setpos(start_frame)\\n    \\n    # Read the chunk from the wav file\\n    chunk_data = wav_file.readframes(end_frame - start_frame)\\n    \\n    # Create a new AudioSegment object from the chunk data\\n    chunk = AudioSegment(\\n        data=chunk_data,\\n        sample_width=wav_file.getsampwidth(),\\n        frame_rate=wav_file.getframerate(),\\n        channels=wav_file.getnchannels()\\n    )\\n    \\n    # Export the chunk as a new wav file\\n    #chunk.export(f\"chunk_{i}.wav\", format=\"wav\")\\n    segments.append(chunk)\\n    \\n# Close the wav file\\nwav_file.close()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2ts5gg3ro352"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.transcribe('/content/output.wav')\n",
        "\n"
      ],
      "metadata": {
        "id": "CA9NNw1Zo7gB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "text = ''\n",
        "result = []\n",
        "results = []\n",
        "for index in range(len(segments)):\n",
        "  result = model.transcribe(f\"/content/chunk_{index}.wav\")\n",
        "  text = text + result['text']\n",
        "'''"
      ],
      "metadata": {
        "id": "SgABsMv490yh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "db5f66d5-629d-4e10-c1a7-461d7b71d9be"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ntext = \\'\\'\\nresult = []\\nresults = []\\nfor index in range(len(segments)):\\n  result = model.transcribe(f\"/content/chunk_{index}.wav\")\\n  text = text + result[\\'text\\']\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result['text']"
      ],
      "metadata": {
        "id": "m8faRsHX9nNu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8e7ece93-0fe4-4dc9-bfc7-2335d5598caa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Good afternoon, everyone. Thank you all for joining today. My name is Alexander Amini, and I'll be one of your course organizers this year along with Ava. And together, we're super excited to introduce you all to Introduction to Deep Learning. Now, MIT Intro to Deep Learning is a really, really fun, exciting, and fast-paced program here at MIT. And let me start by just, first of all, giving you a little bit of background into what we do and what you're going to learn about this year. So this week of Intro to Deep Learning, we're going to cover a ton of material in just one week. You'll learn the foundations of this really, really fascinating and exciting field of deep learning and artificial intelligence. And more importantly, you're going to get hands-on experience actually reinforcing what you learn in the lectures as part of hands-on software labs. Now, over the past decade, AI and deep learning have really had a huge resurgence and had incredible successes. And a lot of problems that even just a decade ago, we thought were not really even solvable in the near future, now we're solving with deep learning with incredible ease. Now, this past year in particular of 2022 has been an incredible year for deep learning progress. And I'd like to say that actually, this past year in particular has been the year of generative deep learning, using deep learning to generate brand new types of data that have never been seen before and never existed in reality. In fact, I want to start this class by actually showing you how we started this class several years ago, which was by playing this video that I'll play in a second. Now, this video actually was an introductory video for the class. And kind of exemplifies this idea that I'm talking about. So let me just stop there and play this video first of all. Hi, everybody. And welcome to MIT Fit Pass 191, the official introductory course on deep learning taught here at MIT. Deep learning is revolutionizing so many fields, from robotics to medicine and everything in between. You'll learn the fundamentals of this field and how you can build some of these incredible algorithms. In fact, this entire speech and video are not real and were created using deep learning and artificial intelligence. And in this class, you'll learn how. It has been an honor to speak with you today. And I hope you enjoy the course. So in case you couldn't tell, this video and its entire audio was actually not real. It was synthetically generated by a deep learning algorithm. And when we introduced this class a few years ago, this video was created several years ago. But even several years ago, when we introduced this and put it on YouTube, it went somewhat viral. People really loved this video. They were intrigued by how real the video and audio felt and looked, entirely generated by an algorithm, by a computer. And people were shocked with the power and the realism of these types of approaches. And this was a few years ago. Now fast forward to today and the state of deep learning today, we have seen deep learning accelerating at a rate faster than we've ever seen before. In fact, we can use deep learning now to generate not just images of faces, but generate full synthetic environments where we can train autonomous vehicles entirely in simulation and deploy them on full scale vehicles in the real world seamlessly. The videos here you see are actually from a data-driven simulator from neural networks generated called Vista that we actually built here at MIT and have open sourced to the public. So all of you can actually train and build a future of autonomy and self-driving cars. And of course, it goes far beyond this as well. Deep learning can be used to generate content directly from how we speak and the language that we convey to it from prompts that we say. Deep learning can reason about the prompts in natural language, in English, for example, and then guide and control what is generated according to what we specify. We've seen examples of where we can generate, for example, things that, again, have never existed in reality. We can ask a neural network to generate a photo of a astronaut riding a horse. And it actually can imagine, hallucinate what this might look like, even though, of course, this photo, not only this photo has never occurred before, but I don't think any photo of an astronaut riding a horse has ever occurred before. So there's not really even training data that you could go off in this case. And my personal favorite is actually how we can not only build software that can generate images and videos, but build software that can generate software as well. We can also have algorithms that can take language prompts. For example, a prompt like this, write code in TensorFlow to generate or to train a neural network. And not only will it write the code and create that neural network, but it'll have the ability to reason about the code that it's generating and walk you through, step by step, explaining the process and procedure all the way from the ground up to you so that you can actually learn how to do this process as well. Now, I think some of these examples really just highlight how far deep learning and these methods have come in the past six years since we started this course. And you saw that example just a few years ago from that introductory video. But now we're seeing such incredible advances. And the most amazing part of this course, in my opinion, is actually that within this one week, we're going to take you through from the ground up, starting from today, all of the foundational building blocks that will allow you to understand and make all of this amazing advances possible. So with that, hopefully now you're all super excited about what this class will teach. And I want to basically now just start by taking a step back and introducing some of these terminologies that I've been throwing around so far, with deep learning, artificial intelligence, what do these things actually mean? So first of all, I want to maybe just take a second to speak a little bit about intelligence and what intelligence means at its core. So to me, intelligence is simply the ability to process information such that we can use it to inform some future decision or action that we take. Now, the field of artificial intelligence is simply the ability for us to build algorithms, artificial algorithms, that can do exactly this, process information to inform some future decision. Now, machine learning is simply a subset of AI, which focuses specifically on how we can build a machine to, or teach a machine, how to do this from some experiences or data, for example. Now, deep learning goes one step beyond this and is a subset of machine learning, which focuses explicitly on what are called neural networks and how we can build neural networks that can extract features in the data. These are basically what you can think of as patterns that occur within the data so that it can learn to complete these tasks as well. Now, that's exactly what this class is really all about at its core. We're going to try and teach you and give you the foundational understanding in how we can build and teach computers to learn tasks, many different type of tasks, directly from raw data. And that's really what this class boils down to at its most simple form. And we'll provide a very solid foundation for you, both on the technical side through the lectures, which will happen in two parts throughout the class, the first lecture and the second lecture, each one about one hour long, followed by a software lab, which will immediately follow the lectures, which will try to reinforce a lot of what we cover in the technical part of the class and give you hands-on experience implementing those ideas. So this program is split between these two pieces, the technical lectures and the software labs. We have several new updates this year in specific, especially in many of the later lectures. The first lecture will cover the foundations of deep learning, which is going to be right now. And finally, we'll conclude the course with some very exciting guest lectures from both academia and industry who are really leading and driving forward the state of AI and deep learning. And of course, we have many awesome prizes that go with all of the software labs and the project competition at the end of the course. So maybe quickly to go through these. Each day, like I said, we'll have dedicated software labs that couple with the lectures. Starting today with lab one, you'll actually build a neural network. Keeping with this theme of generative AI, you'll build a neural network that can listen to a lot of music and actually learn how to generate brand new songs in that genre of music. At the end, at the next level of the class on Friday, we'll host a project pitch competition where either you individually or as part of a group can participate and present an idea, a novel deep learning idea, to all of us. It'll be roughly three minutes in length. And we will focus not as much because this is a one week program. We are not going to focus so much on the results of your pitch, but rather the innovation and the idea and the novelty of what you're trying to propose. The prizes here are quite significant already. We're first prize is going to get an NVIDIA GPU, which is really a key piece of hardware that is instrumental. If you want to actually build a deep learning project and train these neural networks, which can be very large and require a lot of compute, these prizes will give you the compute to do so. And finally, this year we'll be awarding a grand prize for labs two and three combined, which will occur on Tuesday and Wednesday, focused on what I believe is actually solving some of the most exciting problems in this field of deep learning, and specifically how we can build models that can be robust, not only accurate, but robust and trustworthy and safe when they're deployed as well. And you'll actually get experience developing those types of solutions that can actually advance the state of the art in AI. Now, all of these labs that I mentioned and competitions here are going to be due on Thursday night at 11 PM, right before the last day of class. And we'll be helping you all along the way. This prize, or this competition in particular, has very significant prizes. So I encourage all of you to really enter this prize and try to get a chance to win the prize. And of course, like I said, we're going to be helping you all along the way. There are many available resources throughout this class to help you achieve this. Please post to Piazza if you have any questions. And of course, this program has an incredible team that you can reach out to at any point in case you have any issues or questions on the materials. Myself and Ava will be your two main lecturers for the first part of the class. We'll also be hearing, like I said, in the later part of the class, from some guest lectures who will share some really cutting edge state of the art developments in deep learning. And of course, I want to give a huge shout out and thanks to all of our sponsors who, without their support, this program wouldn't have been possible for yet again another year. So thank you all. OK, so now with that, let's really dive into the really fun stuff of today's lecture, which is the technical part. And I think I want to start this part by asking all of you and having you ask yourselves this question of, why are all of you here, first of all? Why do you care about this topic in the first place? Now, I think to answer this question, we have to take a step back and think about the history of machine learning and what machine learning is and what deep learning brings to the table on top of machine learning. Now, traditional machine learning algorithms typically define what are called these set of features in the data. You can think of these as certain patterns in the data. And then usually, these features are hand engineered. So probably a human will come into the data set and with a lot of domain knowledge and experience can try to uncover what these features might be. Now, the key idea of deep learning, and this is really central to this class, is that instead of having a human define these features, what if we could have a machine look at all of this data and actually try to extract and uncover what are the core patterns in the data so that it can use those when it sees new data to make some decisions? So for example, if we wanted to detect faces in an image, a deep neural network algorithm might actually learn that in order to detect a face, it first has to detect things like edges in the image, lines and edges. And when you combine those lines and edges, you can actually create compositions of features like corners and curves, which when you combine those, you can create more high level features, for example, eyes and noses and ears. And then those are the features that allow you to ultimately detect what you care about detecting, which is the face. But all of these come from what are called kind of a hierarchical learning of features. And you can actually see some examples of these. These are real features learned by a neural network and how they're combined defines this progression of information. But in fact, what I just described, this underlying and fundamental building block of neural networks and deep learning have actually existed for decades. Now, why are we studying all of this now and today in this class with all this great enthusiasm to learn this, right? Well, for one, there have been several key advances that have occurred in the past decade. Number one is that data is so much more pervasive than it has ever been before in our lifetimes. These models are hungry for more data. And we're living in the age of big data. More data is available to these models than ever before, and they thrive off of that. Secondly, these algorithms are massively parallelizable. They require a lot of compute. And we're also at a unique time in history where we have the ability to train these extremely large-scale algorithms and techniques that have existed for a very long time, but we can now train them due to the hardware advances that have been made. And finally, due to open-source toolboxes and software platforms like TensorFlow, for example, which all of you will get a lot of experience on in this class, training and building the code for these neural networks has never been easier. So from the software point of view as well, there have been incredible advances to open-source the underlying fundamentals of what you're going to learn. So let me start now with just building up from the ground up the fundamental building block of every single neural network that you're going to learn in this class. And that's going to be just a single neuron. And in neural network language, a single neuron is called a perceptron. So what is a perceptron? A perceptron is, like I said, a single neuron. And it's actually, I'm going to say, it's a very, very simple idea. So I want to make sure that everyone in the audience understands exactly what a perceptron is and how it works. So let's start by first defining a perceptron as taking as input a set of inputs. So on the left-hand side, you can see this perceptron takes M different inputs, one to M. These are the blue circles. We're denoting these inputs as Xs. Each of these numbers, each of these inputs is then multiplied by a corresponding weight, which we can call W. So X1 will be multiplied by W1. And we'll add the result of all of these multiplications together. Now, we take that single number after the addition and we pass it through this nonlinear, what we call a nonlinear activation function. And that produces our final output of the perceptron, which we can call Y. Now, this is actually not entirely accurate of the picture of a perceptron. There's one step that I forgot to mention here. So in addition to multiplying all of these inputs with their corresponding weights, we're also now going to add what's called a bias term, here denoted as this W0, which is just a scalar weight. And you can think of it coming with a input of just one. So that's going to allow the network to basically shift its nonlinear activation function, nonlinearly, as it sees its inputs. Now, on the right-hand side, you can see this diagram mathematically formulated. As a single equation, we can now rewrite this linear, this equation with linear algebra, terms of vectors and dot products. So for example, we can define our entire inputs, X1 to Xm, as large vector X. That large vector X can be multiplied by, or take a dot, excuse me, matrix multiplied with our weights, W. That's again, another vector of our weights, W1 to Wm. Taking their dot product, not only multiplies them, but it also adds the resulting terms together. Adding a bias, like we said before, and applying this nonlinearity. Now, you might be wondering, what is this nonlinear function? I've mentioned it a few times already. Well, I said it is a function, right, that we pass the outputs of the neural network through before we return it to the next neuron in the pipeline. So one common example of a nonlinear function that's very popular in deep neural networks is called the sigmoid function. You can think of this as kind of a continuous version of a threshold function, right? It goes from zero to one, and it can take as input any real number on the real number line. And you can see an example of it illustrated on the bottom right hand. Now, in fact, there are many types of nonlinear activation functions that are popular in deep neural networks, and here are some common ones. And throughout this presentation, you'll actually see some examples of these code snippets on the bottom of the slides, where we'll try and actually tie in some of what you're learning in the lectures to actual software and how you can implement these pieces, which will help you a lot for your software labs explicitly. So the sigmoid activation on the left is very popular since it's a function that outputs between zero and one. So especially when you want to deal with probability distributions, for example, this is very important because probabilities live between zero and one. In modern deep neural networks, though, the ReLU function, which you can see on the far right hand, is a very popular activation function because it's piecewise linear. It's extremely efficient to compute, especially when computing its derivatives, right? Its derivatives are constants, except for one nonlinearity at zero. Now, I hope actually all of you are probably asking this question to yourself of, why do we even need this nonlinear activation function? It seems like it kind of just complicates this whole picture when we didn't really need it in the first place. And I want to just spend a moment on answering this because the point of a nonlinear activation function is, of course, number one, is to introduce nonlinearities to our data, right? If we think about our data, almost all data that we care about, all real world data is highly nonlinear. Now, this is important because if we want to be able to deal with those types of data sets, we need models that are also nonlinear so they can capture those same types of patterns. So imagine I told you to separate, for example, I gave you this data set, red points from green points, and I asked you to try and separate those two types of data points. Now, you might think that this is easy, but what if I could only, what if I told you that you could only use a single line to do so? Well, now it becomes a very complicated problem. In fact, you can't really solve it effectively with a single line. And in fact, if you introduce nonlinear activation functions to your solution, that's exactly what allows you to deal with these types of problems. Nonlinear activation functions allow you to deal with nonlinear types of data. Now, and that's what exactly makes neural networks so powerful at their core. So let's understand this maybe with a very simple example, walking through this diagram of a perceptron one more time. Imagine I give you this trained neural network with weights now not w1, w2. I'm going to actually give you numbers at these locations. So the trained weights, w0 will be one, and w will be a vector of three and negative two. So this neural network has two inputs. Like we said before, it has input x1 and it has input x2. If we want to get the output of it, this is also the main thing I want all of you to take away from this lecture today is that to get the output of a perceptron, there are three steps we need to take. From this stage, we first compute the multiplication of our inputs with our weights. Sorry, yeah, multiply them together, add their result, and compute a nonlinearity. It's these three steps that define the forward propagation of information through a perceptron. So let's take a look at how that exactly works. So if we plug in these numbers to those equations, we can see that everything inside of our nonlinearity, here the nonlinearity is g, that function g, which could be a sigmoid, we saw a previous slide. That component inside of our nonlinearity is in fact just a two-dimensional line. It has two inputs, and if we consider the space of all of the possible inputs that this neural network could see, we can actually plot this on a decision boundary. We can plot this two-dimensional line as a decision boundary, as a plane separating these two components of our space. In fact, not only is it a single plane, there's a directionality component, depending on which side of the plane that we live on. If we see an input, for example here, negative one, two, we actually know that it lives on one side of the plane, and it will have a certain type of output. In this case, that output is going to be positive, right? Because in this case, when we plug those components into our equation, we'll get a positive number that passes through the nonlinear component, and that gets propagated through as well. Of course, if you're on the other side of the space, you're going to have the opposite result, right? And that thresholding function is going to essentially live at this decision boundary. So depending on which side of the space you live on, that thresholding function, that sigmoid function, is going to then control how you move to one side or the other. Now, in this particular example, this is very convenient, because we can actually visualize, and I can draw this exact full space for you on this slide. It's only a two-dimensional space, so it's very easy for us to visualize. But of course, for almost all problems that we care about, our data points are not going to be two-dimensional. If you think about an image, the dimensionality of an image is going to be the number of pixels that you have in the image, right? So these are going to be thousands of dimensions, millions of dimensions, or even more. And then drawing these types of plots, like you see here, is simply not feasible, right? So we can't always do this, but hopefully this gives you some intuition to understand kind of as we build up into more complex models. So now that we have an idea of the perceptron, let's see how we can actually take this single neuron and start to build it up into something more complicated, a full neural network, and build a model from that. So let's revisit, again, this previous diagram of the perceptron. If, again, just to reiterate one more time, this core piece of information that I want all of you to take away from this class is how a perceptron works and how it propagates information to its decision. There are three steps. First is the dot product, second is the bias, and third is the non-linearity. And you keep repeating this process for every single perceptron in your neural network. Let's simplify the diagram a little bit. I'll get rid of the weights, and you can assume that every line here now basically has an associated weight scaler that's associated with it. It corresponds to the input that's coming in. It has a weight that's coming in also on the line itself. And I've also removed the bias just for sake of simplicity, but it's still there. So now the result is that z, which let's call that the result of our dot product plus the bias, and that's what we pass into our nonlinear function. That piece is going to be applied to that activation function. Now the final output here is simply going to be g, which is our activation function, of z. Z is going to be basically, you can think of the state of this neuron. It's the result of that dot product plus bias. Now if we want to define and build up a multilayered output neural network, if we want two outputs to this function, for example, it's a very simple procedure. We just have now two neurons, two perceptrons. Each perceptron will control the output for its associated piece. So now we have two outputs. Each one is a normal perceptron. It takes all of the inputs, so they both take the same inputs. But amazingly, now with this mathematical understanding, we can start to build our first neural network entirely from scratch. So what does that look like? So we can start by firstly initializing these two components. The first component that we saw was the weight matrix, excuse me, the weight vector. It's a vector of weights in this case. And the second component is the bias vector that we're going to multiply with the dot product of all of our inputs by our weights. So the only remaining step now, after we've defined these parameters of our layer, is to now define how this forward propagation of information works. And that's exactly those three main components that I've been stressing to you. So we can create this call function to do exactly that, to define this forward propagation of information. And the story here is exactly the same as we've been seeing it. Matrix multiply our inputs with our weights, add a bias, and then apply a non-linearity and return the result. And that literally, this code will run, this will define a full neural network layer that you can then take like this. And of course, actually luckily for all of you, all of that code, which wasn't much code, that's been abstracted away by these libraries like TensorFlow. So you can simply call functions like this, which will actually replicate exactly that piece of code. So you don't need to necessarily copy all of that code down, you can just call it. And with that understanding, we just saw how you could build a single layer, but of course, now you can actually start to think about how you can stack these layers as well. So since we now have this transformation, essentially, from our inputs to a hidden output, you can think of this as basically how we can define some way of transforming those inputs into some new dimensional space, perhaps closer to the value that we want to predict. And that transformation is going to be eventually learned to know how to transform those inputs into our desired outputs, and we'll get to that later. But for now, the piece that I want to really focus on is if we have these more complex neural networks, I want to really distill down that this is nothing more complex than what we've already seen. If we focus on just one neuron in this diagram, take here, for example, Z2, right? Z2 is this neuron that's highlighted in the middle layer. It's just the same perceptron that we've been seeing so far in this class. Its output is obtained by taking a dot product, adding a bias, and then applying that non-linearity between all of its inputs. If we look at a different node, for example, Z3, which is the one right below it, it's the exact same story again. It sees all of the same inputs, but it has a different set of weight matrix that it's going to apply to those inputs. So it'll have a different output. But the mathematical equations are exactly the same. So from now on, I'm just going to kind of simplify all of these lines and diagrams just to show these icons in the middle, just to demonstrate that this means everything is going to be fully connected to everything and defined by those mathematical equations that we've been covering. But there's no extra complexity in these models from what you've already seen. Now, if you want to stack these types of solutions on top of each other, these layers on top of each other, you can not only define one layer very easily, but you can actually create what are called sequential models. These sequential models, you can define one layer after another, and they define basically the forward propagation of information, not just from the neuron level, but now from the layer level. Every layer will be fully connected to the next layer. And the inputs of the secondary layer will be all of the outputs of the prior layer. Now, of course, if you want to create a very deep neural network, all a deep neural network is is we just keep stacking these layers on top of each other. There's nothing else to this story. That's really as simple as it is. So these layers are basically, all they are is just layers where the final output is computed by going deeper and deeper into this progression of different layers. And you just keep stacking them until you get to the last layer, which is your output layer. It's your final prediction that you want to output. Right, we can create a deep neural network to do all of this by stacking these layers and creating these more hierarchical models like we saw very early in the beginning of today's lecture, one where the final output is really computed by just going deeper and deeper into this system. Okay, so that's awesome. So we've now seen how we can go from a single neuron to a layer, all the way to a deep neural network, building off of these foundational principles. Let's take a look at how exactly we can use these principles that we've just discussed to solve a very real problem that I think all of you are probably very concerned about this morning when you woke up. So that problem is how we can build a neural network to answer this question, which is, will I pass this class, and if I will, will I not? So to answer this question, let's see if we can train a neural network to solve this problem. So to do this, let's start with a very simple neural network. We'll train this model with two inputs, just two inputs. One input is going to be the number of lectures that you attend over the course of this one week, and the second input is going to be how many hours that you spend on your final project or your competition. Okay, so what we're going to do is firstly go out and collect a lot of data from all of the past years that we've taught this course, and we can plot all of this data. Because it's only two input space, we can plot this data on a two-dimensional feature space. We can actually look at all of the students before you that have passed the class and failed the class and see where they lived in this space for the amount of hours that they've spent, the number of lectures that they've attended, and so on. Green points are the people who have passed, red are those who have failed. Now, and here's you, right? You're right here, four, five is your coordinate space. You fall right there, and you've attended four lectures, you've spent five hours on your final project. We want to build a neural network to answer the question of will you pass the class or will you fail the class? So let's do it. We have two inputs, one is four, one is five. These are two numbers, we can feed them through a neural network that we've just seen how we can build that, and we feed that into a single-layered neural network, three hidden units in this example, but we could make it larger if we wanted to be more expressive and more powerful. And we see here that the probability of you passing this class is 0.1. It's pretty dismal. So why would this be the case, right? What did we do wrong? Because I don't think it's correct, right? When we looked at the space, it looked like actually you were a good candidate to pass the class, but why is the neural network saying that there's only 10% likelihood that you should pass? Does anyone have any ideas? Exactly, exactly. So this neural network is just like it was just born, right? It has no information about the world or this class, it doesn't know what four and five mean or what the notion of passing or failing means, right? So exactly right, this neural network has not been trained. You can think of it kind of as a baby. It hasn't learned anything yet. So our job, firstly, is to train it. And part of that understanding is we first need to tell the neural network when it makes mistakes, right? So mathematically, we should now think about how we can answer this question, which is, did my neural network make a mistake? And if it made a mistake, how can I tell it how big of a mistake it was so that the next time it sees this data point, can it do better, minimize that mistake? So in neural network language, those mistakes are called losses, right? And specifically, you want to define what's called a loss function, which is going to take as input your prediction and the true prediction, right? And how far away your prediction is from the true prediction tells you how big of a loss there is, right? So for example, let's say we want to build a neural network to do classification of, or sorry, actually even before that, I want to maybe give you some terminology. So there are multiple different ways of saying the same thing in neural networks and deep learning. So what I just described as a loss function is also commonly referred to as an objective function, empirical risk, a cost function. These are all exactly the same thing. They're all a way for us to train the neural network, to teach the neural network when it makes mistakes. And what we really ultimately want to do is over the course of an entire data set, not just one data point of mistakes, we want to say over the entire data set, we want to minimize all of the mistakes on average that this neural network makes. So if we look at the problem, like I said, of binary classification, will I pass this class or will I not? There's a yes or no answer. That means binary classification. Now, we can use what's called a loss function of the softmax cross-entropy loss. And for those of you who aren't familiar, this notion of cross-entropy is actually developed here at MIT by Shawn, excuse me, yes, Claude Shannon, who is a visionary. He did his master's here over 50 years ago. He introduced this notion of cross-entropy and that was pivotal in the ability for us to train these types of neural networks, even now into the future. So let's start by, instead of predicting a binary cross-entropy output, what if we wanted to predict a final grade of your class score, for example? That's no longer a binary output, yes or no. It's actually a continuous variable, right? It's the grade, let's say out of 100 points, what is the value of your score in the class project, right? For this type of loss, we can use what's called a mean squared error loss. You can think of this literally as just subtracting your predicted grade from the true grade and minimizing that distance apart. So I think now we're ready to really put all of this information together and tackle this problem of training a neural network, right, to not just identify how erroneous it is, how large its loss is, but more importantly, minimize that loss as a function of seeing all of this training data that it observes. So we know that we want to find this neural network, like we mentioned before, that minimizes this empirical risk or this empirical loss averaged across our entire data set. Now this means that we want to find, mathematically, these W's, right, that minimize J of W. J of W is our loss function averaged over our entire data set, and W is our weight. So we want to find the set of weights that, on average, is going to give us the smallest loss as possible. Now remember that W here is just a list. Basically, it's just a group of all of the weights in our neural network. You may have hundreds of weights in a very, very small neural network, or in today's neural networks, you may have billions or trillions of weights, and you want to find what is the value of every single one of these weights that's going to result in the smallest loss as possible. Now, how can you do this? Remember that our loss function, J of W, is just a function of our weights, right? So for any instantiation of our weights, we can compute a scalar value of how erroneous would our neural network be for this instantiation of our weights. So let's try and visualize, for example, in a very simple example of a two-dimensional space where we have only two weights. Extremely simple neural network here, very small, two-weight neural network, and we want to find what are the optimal weights that would train this neural network. We can plot, basically, the loss, how erroneous the neural network is for every single instantiation of these two weights. This is a huge space, it's an infinite space, but still, we can have a function that evaluates at every point in this space. Now, what we ultimately want to do is, again, we want to find which set of Ws will give us the smallest loss possible. That means, basically, the lowest point on this landscape that you can see here, where is the Ws that bring us to that lowest point? The way that we do this is actually just by, firstly, starting at a random place. We have no idea where to start, so pick a random place to start in this space, and let's start there. At this location, let's evaluate our neural network. We can compute the loss at this specific location, and on top of that, we can actually compute how the loss is changing. We can compute the gradient of the loss because our loss function is a continuous function. So we can actually compute derivatives of our function across the space of our weights, and the gradient tells us the direction of the highest point. So from where we stand, the gradient tells us where we should go to increase our loss. Now, of course, we don't want to increase our loss. We want to decrease our loss, so we negate our gradient, and we take a step in the opposite direction of the gradient. That brings us one step closer to the bottom of the landscape, and we just keep repeating this process. Over and over again, we evaluate the neural network at this new location, compute its gradient, and step in that new direction. We keep traversing this landscape until we converge to the minimum. We can really summarize this algorithm, which is known formally as gradient descent. So gradient descent simply can be written like this. We initialize all of our weights. This can be two weights, like you saw in the previous example. It can be billions of weights, like in real neural networks. We compute this gradient of the partial derivative of our loss with respect to the weights, and then we can update our weights in the opposite direction of this gradient. So essentially, we just take this small amount, small step, you can think of it, which here is denoted as eta, and we refer to this small step. This is commonly referred to as what's known as the learning rate. It's like how much we want to trust that gradient and step in the direction of that gradient. We'll talk more about this later, but just to give you some sense of code, this algorithm is very well translatable to real code as well. For every line on the pseudocode you can see on the left, you can see corresponding real code on the right that is runnable and directly implementable by all of you in your labs. But now let's take a look specifically at this term here. This is the gradient. We touched very briefly on this in the visual example. This explains, like I said, how the loss is changing as a function of the weights. So as the weights move around, will my loss increase or decrease? And that will tell the neural network if it needs to move the weights in a certain direction or not. But I never actually told you how to compute this, and I think that's an extremely important part because if you don't know that, then you can't train your neural network. This is a critical part of training neural networks. And that process of computing this line, this gradient line, is known as backpropagation. So let's do a very quick intro to backpropagation and how it works. So again, let's start with the simplest neural network in existence. This neural network has one input, one output, and only one neuron. This is as simple as it gets. We want to compute the gradient of our loss with respect to our weight. In this case, let's compute it with respect to W2, the second weight. So this derivative is going to tell us how much a small change in this weight will affect our loss. If a small change, if we change our weight a little bit in one direction, will it increase our loss or decrease our loss? So to compute that, we can write out this derivative. We can start with applying the chain rule backwards from the loss function through the output. Specifically, what we can do is we can actually just decompose this derivative into two components. The first component is the derivative of our loss with respect to our output, multiplied by the derivative of our output with respect to W2. This is just a standard instantiation of the chain rule with this original derivative that we had on the left-hand side. Let's suppose we wanted to compute the gradients of the weight before that, which in this case are not W1, but W, excuse me, not W2, but W1. Well, all we do is replace W2 with W1, and that chain rule still holds, right? That same equation holds, but now you can see on the red component, that last component of the chain rule, we have to, once again, recursively apply one more chain rule because that's, again, another derivative that we can't directly evaluate. We can expand that once more with another instantiation of the chain rule, and now all of these components, we can directly propagate these gradients through the hidden units in our neural network all the way back to the weight that we're interested in in this example, right? So we first computed the derivative with respect to W2, then we can back-propagate that and use that information also with W1. That's why we really call it back-propagation because this process occurs from the output all the way back to the input. Now, we repeat this process essentially many, many times over the course of training by propagating these gradients over and over again through the network all the way from the output to the inputs to determine for every single weight, answering this question, which is, how much does a small change in these weights affect our loss function? If it increases, if it decreases, and how we can use that to improve the loss, ultimately, because that's our final goal in this class. So that's the back-propagation algorithm. That's the core of training neural networks. In theory, it's very simple. It's really just an instantiation of the chain rule. But let's touch on some insights that make training neural networks actually extremely complicated in practice, even though the algorithm of back-propagation is simple and many decades old. In practice, though, optimization of neural networks looks something like this. It looks nothing like that picture that I showed you before. There are ways that we can visualize very large, deep neural networks. And you can think of the landscape of these models looking like something like this. This is an illustration from a paper that came out several years ago, where they tried to actually visualize the landscape of very, very deep neural networks. And that's what this landscape actually looks like. That's what you're trying to deal with and find the minimum in this space. And you can imagine the challenges that come with that. So to cover the challenges, let's first think of and recall that update equation defined in gradient descent. So I didn't talk too much about this parameter, eta. But now let's spend a bit of time thinking about this. This is called the learning rate, like we saw before. It determines basically how big of a step we need to take in the direction of our gradient in every single iteration of back-propagation. In practice, even setting the learning rate can be very challenging. You, as the designer of the neural network, have to set this value, this learning rate. And how do you pick this value? So that can actually be quite difficult. And it has really large consequences when building a neural network. So for example, if we set the learning rate too low, then we learn very slowly. So let's assume we start on the right-hand side here at that initial guess. If our learning rate is not large enough, not only do we converge slowly, we actually don't even converge to the global minimum, because we kind of get stuck in a local minimum. Now, what if we set our learning rate too high? What can actually happen is we overshoot. And we can actually start to diverge from the solution. The gradients can actually explode. Very bad things happen. And then the neural network doesn't train. So that's also not good. In reality, there's a very happy medium between setting it too small, setting it too large, where you set it just large enough to kind of overshoot some of these local minima, put you into a reasonable part of the search space, where then you can actually converge on the solutions that you care most about. But actually, how do you set these learning rates in practice? How do you pick what is the ideal learning rate? One option, and this is actually a very common option in practice, is to simply try out a bunch of learning rates and see what works the best. So try out, let's say, a whole grid of different learning rates and train all of these neural networks, see which one works the best. But I think we can do something a lot smarter. So what are some more intelligent ways that we could do this? Instead of exhaustively trying out a whole bunch of different learning rates, can we design a learning rate algorithm that actually adapts to our neural network and adapts to its landscape so that it's a bit more intelligent than that previous idea? So this really ultimately means that the learning rate, the speed at which the algorithm is trusting the gradients that it sees, is going to depend on how large the gradient is in that location and how fast we're learning, how many other options, and many other options that we might have as part of training a neural network. So it's not only how quickly we're learning. You may judge it on many different factors in the learning landscape. In fact, we've all been, these different algorithms that I'm talking about, these adaptive learning rate algorithms, have been very widely studied in practice. There is a very thriving community in the deep learning research community that focuses on developing and designing new algorithms for learning rate adaptation and faster optimization of large neural networks like these. And during your labs, you'll actually get the opportunity to not only try out a lot of these different adaptive algorithms, which you can see here, but also try to uncover what are the patterns and benefits of one versus the other. And that's going to be something that I think you'll find very insightful as part of your labs. So another key component of your labs that you'll see is how you can actually put all of this information that we've covered today into a single picture that looks roughly something like this, which defines your model at the first, at the top here. That's where you define your model. We talked about this in the beginning part of the lecture. For every piece in your model, you're now going to need to define this optimizer, which we just talked about. This optimizer is defined together with a learning rate, how quickly you want to optimize your lost landscape. And over many loops, you're going to pass over all of the examples in your data set and observe, essentially, how to improve your network. That's the gradient. And then actually improve the network in those directions. And keep doing that over and over and over again until eventually your neural network converges to some sort of solution. So I want to very quickly, briefly, in the remaining time that we have, continue to talk about tips for training these neural networks in practice and focus on this very powerful idea of batching your data into what are called mini-batches of smaller pieces of data. To do this, let's revisit that gradient descent algorithm. So here, this gradient that we talked about before is actually extraordinarily computationally expensive to compute because it's computed as a summation across all of the pieces in your data set. And in most real life or real world problems, it's simply not feasible to compute a gradient over your entire data set. Data sets are just too large these days. So there are some alternatives. What are the alternatives? Instead of computing the derivative or the gradients across your entire data set, what if you instead computed the gradient over just a single example in your data set? Just one example. Well, of course, this estimate of your gradient is going to be exactly that. It's an estimate. It's going to be very noisy. It may roughly reflect the trends of your entire data set. But because it's only one example, in fact, of your entire data set, it may be very noisy. Well, the advantage of this, though, is that it's much faster to compute, obviously, the gradient over a single example because it's one example. So computationally, this has huge advantages. But the downside is that it's extremely stochastic. That's the reason why this algorithm is not called gradient descent. It's called stochastic gradient descent now. Now, what's the middle ground? Instead of computing it with respect to one example in your data set, what if we computed what's called a mini-batch of examples, a small batch of examples that we can compute the gradients over? And when we take these gradients, they're still computationally efficient to compute because it's a mini-batch. It's not too large. Maybe we're talking on the order of tens or hundreds of examples in our data set. But more importantly, because we've expanded from a single example to maybe 100 examples, the stochasticity is significantly reduced, and the accuracy of our gradient is much improved. So normally, we're thinking of batch sizes, mini-batch sizes, roughly on the order of 100 data points, tens or hundreds of data points. This is much faster, obviously, to compute than gradient descent and much more accurate to compute compared to stochastic gradient descent, which is that single point example. So this increase in gradient accuracy allows us to essentially converge to our solution much quicker than it could have been possible in practice due to gradient descent limitations. It also means that we can increase our learning rate because we can trust each of those gradients much more efficiently. We're now averaging over a batch. It's going to be much more accurate than the stochastic version, so we can increase that learning rate and actually learn faster as well. This allows us to also massively parallelize this entire algorithm and computation. We can split up batches onto separate workers and achieve even more significant speed-ups of this entire problem using GPUs. The last topic that I very, very briefly want to cover in today's lecture is this topic of overfitting. When we're optimizing a neural network with stochastic gradient descent, we have this challenge of what's called overfitting. Overfitting looks like this, roughly. So on the left-hand side, we want to build a neural network, or let's say in general, we want to build a machine learning model that can accurately describe some patterns in our data. But remember, ultimately, we don't want to describe the patterns in our training data. Ideally, we want to define the patterns in our test data. Of course, we don't observe test data. We only observe training data. So we have this challenge of extracting patterns from training data and hoping that they generalize to our test data. So set in one different way, we want to build models that can learn representations from our training data that can still generalize, even when we show them brand new unseen pieces of test data. So assume that you want to build a line that can describe or find the patterns in these points that you can see on the slide. If you have a very simple neural network, which is just a single line, straight line, you can describe this data suboptimally, because the data here is nonlinear. You're not going to accurately capture all of the nuances and subtleties in this data set. That's on the left-hand side. If you move to the right-hand side, you can see a much more complicated model. But here, you're actually overexpressive. You're too expressive. And you're capturing the nuances, the spurious nuances in your training data that are actually not representative of your test data. Ideally, you want to end up with the model in the middle, which is basically the middle ground. It's not too complex. And it's not too simple. It still gives you what you want to perform well, and even when you give it brand new data. So to address this problem, let's briefly talk about what's called regularization. Regularization is a technique that you can introduce to your training pipeline to discourage complex models from being learned. Now, as we've seen before, this is really critical, because neural networks are extremely large models. They are extremely prone to overfitting. So regularization and having techniques for regularization has extreme implications towards the success of neural networks and having them generalized beyond training data far into our testing domain. The most popular technique for regularization in deep learning is called dropout. And the idea of dropout is actually very simple. Let's revisit it by drawing this picture of deep neural networks that we saw earlier in today's lecture. In dropout during training, we essentially randomly select some subset of the neurons in this neural network. And we try to prune them out with some random probability. So for example, we can select this subset of neurons. We can randomly select them with a probability of 50%. And with that probability, we randomly turn them off or on on different iterations of our training. So this is essentially forcing the neural network to learn you can think of an ensemble of different models. On every iteration, it's going to be exposed to a different model internally than the one it had on the last iteration. So it has to learn how to build internal pathways to process the same information. And it can't rely on information that it learned on previous iterations. So it forces it to capture some deeper meaning within the pathways of the neural network. And this can be extremely powerful because number one, it lowers the capacity of the neural network significantly. You're lowering it by roughly 50% in this example. But also because it makes them easier to train because the number of weights that have gradients in this case is also reduced. So it's actually much faster to train them as well. Now like I mentioned, on every iteration, we randomly drop out a different set of neurons. And that helps the data generalize better. And the second regularization techniques, which is actually a very broad regularization technique far beyond neural networks, is simply called early stopping. Now we know that the definition of overfitting is simply when our model starts to represent basically the training data more than the testing data. That's really what overfitting comes down to at its core. If we set aside some of the training data to use separately that we don't train on, we can use it as kind of a testing data set, synthetic testing data set in some ways, we can monitor how our network is learning on this unseen portion of data. So for example, over the course of training, we can basically plot the performance of our network on both the training set as well as our held out test set. And as the network is trained, we're going to see that first of all, these both decrease. But there's going to be a point where the loss plateaus and starts to increase. The training loss will actually start to increase. This is exactly the point where you start to overfit. Because now you're starting to have, sorry, that was the test loss. The test loss actually starts to increase because now you're starting to overfit on your training data. This pattern basically continues for the rest of training. And this is the point that I want you to focus on. This middle point is where we need to stop training because after this point, assuming that this test set is a valid representation of the true test set, this is the place where the accuracy of the model will only get worse. So this is where we would want to early stop our model and regularize the performance. And we can see that stopping any time before this point is also not good. We're going to produce an underfit model where we could have had a better model on the test data. But it's this trade-off. You can't stop too late and you can't stop too early as well. So I'll conclude this lecture by just summarizing these three key points that we've covered in today's lecture so far. So we first covered these fundamental building blocks of all neural networks, which is the single neuron, the perceptron. We've built these up into larger neural layers and then from there, neural networks and deep neural networks. We've learned how we can train these, apply them to data sets, back propagate through them. And we've seen some tricks, tips and tricks for optimizing these systems end to end. In the next lecture, we'll hear from Ava on deep sequence modeling using RNNs and specifically this very exciting new type of model called the transformer architecture and attention mechanisms. So maybe let's resume the class in about five minutes after we have a chance to swap speakers. And thank you so much for all of your attention. Thank you.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVdnZI-lzMVS",
        "outputId": "a0839de4-f1ae-4b90-c1b2-2f747b2c83e2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "summarizer = pipeline(\"summarization\", model=\"philschmid/bart-large-cnn-samsum\")\n",
        "\n",
        "                                       \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "a0ddbf9949fd40b0a8136ab436a4e077",
            "f4c8409b05024d0fb55fdd5121948365",
            "ca3abbf388ce4366ae39e9bfad7ce14a",
            "22b15e154f85455da1572bbb6e59a219",
            "fe4771eca42a446ab67c2c5af0d5a1a1",
            "7abd8b940e624c83ab62f0a6d1957d2d",
            "fbefa4622e4c45de93aad6fdb284e180",
            "5a33fe83c3e449fba48783638c173309",
            "98373ffe87164dd681d74b8bfa35d69c",
            "aa75eaf42132438cb48d45b24020f811",
            "c68bd976c5024b0aaaf7636711b6f902",
            "eda4a066e1bc4232a68140c8a9982d57",
            "fffd8bd93fcf424e88aac92c06ef7228",
            "d3b3fe216ba14cb98f829e391e0154a4",
            "542be442b2a34070a0f2b9e3f2053d10",
            "ec014a7da5bb4b3596dc568ef211e1d7",
            "b9b45c808a5a465ca5380544580086c3",
            "5dd1b97cc5e74fd6ad94ff0cc0cba1fb",
            "82d600effcd74b5db81a5389e92e74fb",
            "16982d10cec54ad68ef98bcaa9157387",
            "eabf45cf1842458da886da35714c6fba",
            "ffe9f968659a459db45adbc242ca9eb9",
            "f9895106f11b400985f7d75cb507d16c",
            "084f6302f56042e7994eac05fc50f434",
            "567e2a0e94ce41d696a75b39f7a8fea7",
            "b48a7efd85284a05ba3a90719f9e7d00",
            "16f11b8928e34567987073e69d101de1",
            "c48183227603488a876a7207890d9198",
            "67dbb6dcbb254ac58e226d848ea1933d",
            "afdf334e65d547909f83e8e1e9102744",
            "cd3e7ab64d6f43208f50f823b645918e",
            "e37815bf3a6b48abba1d728d8dcd9423",
            "bba0f9d349fe44b1bc7883b26b0ef597",
            "df2706c9bc6e42dfb63736ab06c12116",
            "d92929ede105428c92c8b7825002244a",
            "0171b3b9fb474209b80bb5a3f869161a",
            "0de4b70fdd184239a9f9e121d2aaf011",
            "0ee283f91f454c15aa71f3a0d3c5df54",
            "ca18c9c94d6a493bbb4c1732776d99e5",
            "f38375c9b56742cdab2dfa42569e789c",
            "bd3b8e8d9d5345769ee9b4a2427924e4",
            "4303a705a015412bb48a8dc6c7e65378",
            "20b43b0869824317a275adade9d19bc0",
            "24292eca7c4946af913d9e6a47030d5a",
            "c259edf8d63b4266af688d48d9b9d110",
            "e797d24f36fd45b79deefbec5f1a614e",
            "e4b9d8a0e4b24b9590c1a7e8f7237b50",
            "c9965c3733d5414b91ba8cc3b139e16a",
            "e3a3f32b687c4bee942cc8a468f33655",
            "f9e126db3a2649838c29e10d18612d08",
            "5450be0a4b0b433eaa30cf493ac724d2",
            "3c263c0111d748c08763d4dc0ecfd644",
            "2adbaed710a5480a88965e330c70e827",
            "e056afa0d2f14372916ced6fd8cdfa9c",
            "090b5f828d434a3db2e54a744e6eef7e",
            "1fda1a8234524a669d79ba1f9adc3ffa",
            "8f46a20967be45778ef0e0f37ec6adb3",
            "a97fa68447cc43c995fc5ff642dfddb2",
            "6d3ebffbb7f34531a7b40d5690dd0829",
            "b15bc735dfd344dd8318385613bb6a90",
            "556b57be2a9746c89a06baaf5a9ef1e6",
            "980dd03c509143a4b19355deaf1b74b6",
            "a35033b00c2a4457b06ad8212107a196",
            "1ab832e1c9d74b47967d16c3f3242aa1",
            "803c503cf77a440db0af909625d6a2e5",
            "2ffac075b19c403d9dd6a3907cc1c482"
          ]
        },
        "id": "aIEuwzu8zClk",
        "outputId": "20d66962-09ed-44d9-930b-9d41d999b4be"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0ddbf9949fd40b0a8136ab436a4e077"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eda4a066e1bc4232a68140c8a9982d57"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/300 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9895106f11b400985f7d75cb507d16c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df2706c9bc6e42dfb63736ab06c12116"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c259edf8d63b4266af688d48d9b9d110"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fda1a8234524a669d79ba1f9adc3ffa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "len(result['text']) / 10"
      ],
      "metadata": {
        "id": "3CslYo-03Yem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = result['text']"
      ],
      "metadata": {
        "id": "-C1gkj1d47iL"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = result['text'][0:1000]"
      ],
      "metadata": {
        "id": "965-JDUR4VDS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summarizer(a)"
      ],
      "metadata": {
        "id": "vJyMs-XcpQ66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad612e0e-e824-4b1e-cbae-067e4d10e182"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': 'Alexander Amini and Ava Amini are organizing the MIT Intro to Deep Learning this year. This week they are going to cover a lot of material in just one week. They are also going to get hands-on experience reinforcing what they learn in the lectures.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraphs = text.split(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "hq29eteu4UHJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(paragraphs)"
      ],
      "metadata": {
        "id": "w1l7XVye-7Fu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc660f1e-b70c-48f9-fbc7-c8ac0c3b722b"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split transcript into chunks of 500 words\n",
        "transcript = result['text']\n",
        "words = transcript.split()\n",
        "chunks = []\n",
        "chunk = \"\"\n",
        "for word in words:\n",
        "    if len(chunk.split()) < 500:\n",
        "        chunk += word + \" \"\n",
        "    else:\n",
        "        chunks.append(chunk.strip())\n",
        "        chunk = \"\"\n",
        "if chunk:\n",
        "    chunks.append(chunk.strip())\n",
        "\n",
        "# Summarize each chunk\n",
        "summaries = []\n",
        "for chunk in chunks:\n",
        "    summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
        "    summaries.append(summary)"
      ],
      "metadata": {
        "id": "CVLHxt-Tn9hy"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eWH0xxF59xe",
        "outputId": "04ea7474-9565-403d-a6dc-ce6c8e23b74b"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Alexander Amini and Ava Amini are organizing the Introduction to Deep Learning at MIT. The course covers the foundations of AI and deep learning and hands-on experience reinforcing what you learn in the lectures as part of hands on software labs.',\n",
              " 'The state of deep learning is accelerating at a faster rate than ever before. Deep learning can be used to generate content directly from how we speak and the language that we convey to it from prompts that we say. The videos you see are from a data-driven simulator from neural networks generated called Vista that we built here at MIT and have open sourced to the public. The most amazing part of the course is going to take you through from the ground up, starting from today,',\n",
              " 'The first lecture of the class is going to cover the foundations of deep learning. The second lecture will be about one hour long. The software lab will follow the lectures. The program is split between the technical lectures and the software labs. The guest lectures from both academia and industry will conclude the course.',\n",
              " 'Starting today you will build a neural network in lab one. On Friday you will have a project pitch competition. The first prize is going to get an NVIDIA GPU. The grand prize is for labs two and three, which will occur on Tuesday and Wednesday.',\n",
              " \"Today's lecture is about the history of machine learning and what deep learning is and what it brings to the table on top of it. The key idea of deep learning, which is central to this class, is that instead of having a human define the features in the data, a machine can extract and uncover the core patterns. \",\n",
              " \"Thanks to advances in technology and open-source toolboxes, training and building the code for neural networks has never been easier. A single neuron is the fundamental building block of every single neural network that you're going to learn in this class.\",\n",
              " \"There are many types of nonlinear activation functions that are popular in deep neural networks. The ReLU function is a piecewise linear and it's efficient to compute. The sigmoid activation on the left is a function that outputs between zero and one.\",\n",
              " 'Nonlinear activation functions allow you to deal with nonlinear types of data. This is what makes neural networks so powerful at their core. To get the output of a perceptron, we need to take three steps: multiplication of our inputs with our weights, multiply them together and compute a nonlinearity.',\n",
              " 'In the class, we learn how a perceptron works and how it propagates information to its decision. There are three steps: the dot product, the bias, and the non-linearity. In the example, the data points are not going to be two-dimensional.',\n",
              " 'With this understanding, we can start to build our first neural network entirely from scratch. We can create a call function to define this forward propagation of information. The code will create a full neural network layer that you can then take like this.',\n",
              " \"In the beginning of today's lecture, we saw how we can go from a single neuron to a layer, all the way to a deep neural network building off of the foundational principles. Today, we are going to train a simple neural network to solve the problem of passing the class.\",\n",
              " \"The probability of you passing this class is 0.1. The neural network has not been trained yet. It has no information about the world or this class. It doesn't know what four and five mean.\",\n",
              " 'In neural networks and deep learning, a loss function is a way for us to train the neural network and teach it when it makes mistakes. Claude Shannon introduced the notion of cross-entropy to train neural networks.',\n",
              " 'In a two-dimensional space where we have only two weights, we want to find which set of Ws will give us the smallest loss possible. The way to do this is by starting at a random place and evaluating the neural network at this location.',\n",
              " \" gradient descent is an algorithm for training neural networks. Backpropagation is a critical part of the algorithm. It explains how the loss is changing as a function of the weights. It's written in pseudocode and translated into real code.\",\n",
              " \"The back-propagation algorithm is the core of training neural networks. In theory, it's an instantiation of the chain rule, but in practice it's more complicated. The landscape of neural networks in training is similar to an illustration from a paper.\",\n",
              " \"The learning rate determines how big of a step we need to take in the direction of our gradient in every iteration of back-propagation. If the learning rate is too low, the neural network learns slowly. If it's too large, the network diverges from the solution. There is a happy medium between setting it too small and too large.\",\n",
              " 'As part of your labs, you will try out different algorithms for learning rate adaptation and faster optimization of large neural networks. In the remaining time, we will talk about tips for training these neural networks in practice and focus on the idea of batching data.',\n",
              " \"Stochastic gradient descent is a new form of gradient descent. It's faster and more accurate than the previous form. Overfitting is a problem when building a machine learning model.\",\n",
              " 'The most popular technique for regularization in deep learning is called dropout. In dropout, we randomly select some subset of the neurons in the neural network and we try to prune them out with some random probability. On every iteration of the training process, the neurons are randomly turned off or on. This makes the data generalize better and faster.',\n",
              " 'In the next lecture, we will hear from Ava on deep sequence modeling using RNNs and a new type of model called the transformer architecture and attention mechanisms.']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    }
  ]
}